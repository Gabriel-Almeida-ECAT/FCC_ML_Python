# -*- coding: utf-8 -*-
"""fcc_cat_dog-Gabriel-resolution.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZcAC6_79HhNHlvCRb9baZ6ctbcNMbLBF
"""

# Commented out IPython magic to ensure Python compatibility.
try:
  # This command only in Colab.
#   %tensorflow_version 2.x
except Exception:
  pass
import tensorflow as tf

from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam, SGD
from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator

import os
import numpy as np
import matplotlib.pyplot as plt

# Get project files
!wget https://cdn.freecodecamp.org/project-data/cats-and-dogs/cats_and_dogs.zip

!unzip cats_and_dogs.zip

PATH = 'cats_and_dogs'

train_dir = os.path.join(PATH, 'train')
validation_dir = os.path.join(PATH, 'validation')
test_dir = os.path.join(PATH, 'test')

# Get number of files in each directory. The train and validation directories
# each have the subdirecories "dogs" and "cats".
total_train = sum([len(files) for r, d, files in os.walk(train_dir)])
total_val = sum([len(files) for r, d, files in os.walk(validation_dir)])
total_test = len(os.listdir(test_dir))

# Variables for pre-processing and training.
batch_size = 8
epochs = 15
IMG_HEIGHT = 150
IMG_WIDTH = 150

from genericpath import isdir
#! ls cats_and_dogs/test
import shutil

dest_dir: str = os.path.join(test_dir, 'test_imgs')

os.makedirs(dest_dir, exist_ok=True)

for img in os.listdir(test_dir):
  if os.path.isfile(os.path.join(test_dir, img)):
    src = os.path.join(test_dir, img)
    dst = os.path.join(dest_dir, img)
    shutil.move(src, dst)

# 3
'''train_image_generator = ImageDataGenerator(
    zca_whitening=True, #ZCA (Zero-phase Component Analysis) whitening => type of data preprocessing that aims to remove redundancy in the data and ensure that the features are uncorrelated and have unit variance.
    rotation_range=20,
    width_shift_range=0.3,
    height_shift_range=0.3,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    vertical_flip=True,
    fill_mode='nearest',
    rescale=1.0/255)

validation_image_generator = ImageDataGenerator(rescale=1.0/255, validation_split=0.2)

test_image_generator = ImageDataGenerator(rescale=1.0/255)'''

# ffc ask to only apply reescale (╯°□°）╯︵ ┻━┻
train_image_generator = ImageDataGenerator(rescale=1.0/255)
validation_image_generator = ImageDataGenerator(rescale=1.0/255)
test_image_generator = ImageDataGenerator(rescale=1.0/255)


train_data_gen = train_image_generator.flow_from_directory(
    directory=train_dir,
    target_size=(IMG_WIDTH, IMG_HEIGHT),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=batch_size,
    shuffle=True,
    keep_aspect_ratio=True,
    seed=49)

val_data_gen = validation_image_generator.flow_from_directory(
    directory=validation_dir,
    target_size=(IMG_WIDTH, IMG_HEIGHT),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=batch_size,
    shuffle=True,
    keep_aspect_ratio=True,
    seed=49)

test_data_gen = test_image_generator.flow_from_directory(
    directory=test_dir,
    target_size=(IMG_WIDTH, IMG_HEIGHT),
    color_mode='rgb',
    class_mode=None,
    batch_size=1,
    shuffle=False,
    keep_aspect_ratio=True,
    seed=49)

# 4
def plotImages(images_arr, probabilities = False):
    fig, axes = plt.subplots(len(images_arr), 1, figsize=(5,len(images_arr) * 3))
    if probabilities is False:
      for img, ax in zip( images_arr, axes):
          ax.imshow(img)
          ax.axis('off')
    else:
      for img, probability, ax in zip( images_arr, probabilities, axes):
          ax.imshow(img)
          ax.axis('off')
          if probability > 0.5:
              ax.set_title("%.2f" % (probability*100) + "% dog")
          else:
              ax.set_title("%.2f" % ((1-probability)*100) + "% cat")
    plt.show()

sample_training_images, _ = next(train_data_gen)
plotImages(sample_training_images[:5])

# 5
train_image_generator = ImageDataGenerator(
    #zca_whitening=True, #ZCA (Zero-phase Component Analysis) whitening => type of data preprocessing that aims to remove redundancy in the data and ensure that the features are uncorrelated and have unit variance.
    rotation_range=15,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    vertical_flip=False,
    fill_mode='nearest',
    rescale=1.0/255)

# 6
train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,
                                                     directory=train_dir,
                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                     class_mode='categorical')

augmented_images = [train_data_gen[0][0][0] for i in range(5)]

plotImages(augmented_images)

# 7
model = Sequential()

# Replicate VGG16 model structure => VGG is made for 224x224 images, maybe not the best mode in this case
# performed horribly
'''model.add(Conv2D(64,kernel_size=(3, 3), activation='relu', padding="same",
                 input_shape=(IMG_WIDTH,IMG_HEIGHT,3)))
model.add(Conv2D(64, kernel_size=(3,3), activation='relu', padding="same"))

model.add(MaxPooling2D(pool_size=(2, 2), strides=2))
model.add(Conv2D(128, kernel_size=(3,3), activation='relu', padding="same"))
model.add(Conv2D(128, kernel_size=(3,3), activation='relu', padding="same"))

model.add(MaxPooling2D(pool_size=(2, 2), strides=2))
model.add(Conv2D(256, kernel_size=(3,3), activation='relu', padding="same"))
model.add(Conv2D(256, kernel_size=(3,3), activation='relu', padding="same"))
model.add(Conv2D(256, kernel_size=(3,3), activation='relu', padding="same"))

model.add(MaxPooling2D(pool_size=(2, 2), strides=2))
model.add(Conv2D(512, kernel_size=(3,3), activation='relu', padding="same"))
model.add(Conv2D(512, kernel_size=(3,3), activation='relu', padding="same"))
model.add(Conv2D(512, kernel_size=(3,3), activation='relu', padding="same"))

model.add(MaxPooling2D(pool_size=(2, 2), strides=2))
model.add(Conv2D(512, kernel_size=(3,3), activation='relu', padding="same"))
model.add(Conv2D(512, kernel_size=(3,3), activation='relu', padding="same"))
model.add(Conv2D(512, kernel_size=(3,3), activation='relu', padding="same"))

model.add(MaxPooling2D(pool_size=(2, 2), strides=2))
model.add(Flatten())
model.add(Dense(4096, activation='relu'))
model.add(Dense(4096, activation='relu'))
model.add(Dense(2, activation='softmax'))'''

model.add(Conv2D(32,kernel_size=(3, 3), activation='relu',
                 input_shape=(IMG_WIDTH,IMG_HEIGHT,3)))

model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))

model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))

model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))

# it appears that more conv2d+MaxPooling layers improve acc a bit, altough the model start to heavly overfit

model.add(Flatten())
model.add(Dense(100, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(2, activation='softmax'))

model.summary()

adam_optmizer = Adam(learning_rate=0.01)
SGD_optmizer = SGD(learning_rate=0.01)
model.compile(loss='categorical_crossentropy',
              optimizer=SGD_optmizer,
              metrics=['accuracy'])

# 8
callbacks_list = [
    keras.callbacks.ModelCheckpoint(
        filepath='model.h5',
        monitor='val_loss', save_best_only=True, verbose=1),
    keras.callbacks.EarlyStopping(monitor='val_loss', patience=10,verbose=1)
]

history = model.fit(x=train_data_gen,
                    steps_per_epoch = train_data_gen.n//train_data_gen.batch_size,
                    epochs=epochs,
                    callbacks = callbacks_list,
                    verbose=1,
                    validation_data = val_data_gen,
                    validation_steps = val_data_gen.n//val_data_gen.batch_size)

# 9
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(epochs)

plt.figure(figsize=(12, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

def loss_acc_validation_graphs(model_history):
    acc = model_history['accuracy']
    val_acc = model_history['val_accuracy']
    loss = model_history['loss']
    val_loss = model_history['val_loss']

    epochs = range(1, len(acc) + 1)

    plt.plot(epochs, acc, 'bo', label='Training acc')
    plt.plot(epochs, val_acc, 'g', label='Validation acc')
    plt.title('Training and validation accuracy')
    plt.legend()

    plt.figure()
    plt.plot(epochs, loss, 'bo', label='Training loss')
    plt.plot(epochs, val_loss, 'g', label='Validation loss')
    plt.title('Training and validation loss')
    plt.legend()
    plt.show()

loss_acc_validation_graphs(history.history)

score = model.evaluate_generator(test_data_gen)
print('Test loss: {:.4}'.format(score[0])) # why is it giving me zero?
print('Test accuracy: {:.4}'.format(score[1]))

# To simply get an array
predict = model.predict_generator(test_data_gen)
probabilities = predict.argmax(axis=-1)

probabilities

# 11
answers =  [1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,
            1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,
            1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,
            1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1,
            0, 0, 0, 0, 0, 0]

correct = 0

for probability, answer in zip(probabilities, answers):
  if round(probability) == answer:
    correct +=1

percentage_identified = (correct / len(answers)) * 100

passed_challenge = percentage_identified >= 63

print(f"Your model correctly identified {round(percentage_identified, 2)}% of the images of cats and dogs.")

if passed_challenge:
  print("You passed the challenge!")
else:
  print("You haven't passed yet. Your model should identify at least 63% of the images. Keep trying. You will get it!")

